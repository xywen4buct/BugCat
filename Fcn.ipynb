{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be61058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://blog.csdn.net/qq_23869697/article/details/85106365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0196f404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential,load_model,Model\n",
    "from tensorflow.keras.layers import Dense,LSTM,Flatten,Dropout,Activation,Input,Conv1D\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# my_seed = 7\n",
    "# tf.compat.v1.set_random_seed(my_seed)\n",
    "# physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# try:\n",
    "#     tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "#     assert tf.config.experimental.get_memory_growth(physical_devices[0])\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a135c5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Conv1D in module keras.layers.convolutional:\n",
      "\n",
      "class Conv1D(Conv)\n",
      " |  Conv1D(*args, **kwargs)\n",
      " |  \n",
      " |  1D convolution layer (e.g. temporal convolution).\n",
      " |  \n",
      " |  This layer creates a convolution kernel that is convolved\n",
      " |  with the layer input over a single spatial (or temporal) dimension\n",
      " |  to produce a tensor of outputs.\n",
      " |  If `use_bias` is True, a bias vector is created and added to the outputs.\n",
      " |  Finally, if `activation` is not `None`,\n",
      " |  it is applied to the outputs as well.\n",
      " |  \n",
      " |  When using this layer as the first layer in a model,\n",
      " |  provide an `input_shape` argument\n",
      " |  (tuple of integers or `None`, e.g.\n",
      " |  `(10, 128)` for sequences of 10 vectors of 128-dimensional vectors,\n",
      " |  or `(None, 128)` for variable-length sequences of 128-dimensional vectors.\n",
      " |  \n",
      " |  Examples:\n",
      " |  \n",
      " |  >>> # The inputs are 128-length vectors with 10 timesteps, and the batch size\n",
      " |  >>> # is 4.\n",
      " |  >>> input_shape = (4, 10, 128)\n",
      " |  >>> x = tf.random.normal(input_shape)\n",
      " |  >>> y = tf.keras.layers.Conv1D(\n",
      " |  ... 32, 3, activation='relu',input_shape=input_shape[1:])(x)\n",
      " |  >>> print(y.shape)\n",
      " |  (4, 8, 32)\n",
      " |  \n",
      " |  >>> # With extended batch shape [4, 7] (e.g. weather data where batch\n",
      " |  >>> # dimensions correspond to spatial location and the third dimension\n",
      " |  >>> # corresponds to time.)\n",
      " |  >>> input_shape = (4, 7, 10, 128)\n",
      " |  >>> x = tf.random.normal(input_shape)\n",
      " |  >>> y = tf.keras.layers.Conv1D(\n",
      " |  ... 32, 3, activation='relu', input_shape=input_shape[2:])(x)\n",
      " |  >>> print(y.shape)\n",
      " |  (4, 7, 8, 32)\n",
      " |  \n",
      " |  Args:\n",
      " |    filters: Integer, the dimensionality of the output space\n",
      " |      (i.e. the number of output filters in the convolution).\n",
      " |    kernel_size: An integer or tuple/list of a single integer,\n",
      " |      specifying the length of the 1D convolution window.\n",
      " |    strides: An integer or tuple/list of a single integer,\n",
      " |      specifying the stride length of the convolution.\n",
      " |      Specifying any stride value != 1 is incompatible with specifying\n",
      " |      any `dilation_rate` value != 1.\n",
      " |    padding: One of `\"valid\"`, `\"same\"` or `\"causal\"` (case-insensitive).\n",
      " |      `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly\n",
      " |      to the left/right or up/down of the input such that output has the same\n",
      " |      height/width dimension as the input.\n",
      " |      `\"causal\"` results in causal (dilated) convolutions, e.g. `output[t]`\n",
      " |      does not depend on `input[t+1:]`. Useful when modeling temporal data\n",
      " |      where the model should not violate the temporal order.\n",
      " |      See [WaveNet: A Generative Model for Raw Audio, section\n",
      " |        2.1](https://arxiv.org/abs/1609.03499).\n",
      " |    data_format: A string,\n",
      " |      one of `channels_last` (default) or `channels_first`.\n",
      " |    dilation_rate: an integer or tuple/list of a single integer, specifying\n",
      " |      the dilation rate to use for dilated convolution.\n",
      " |      Currently, specifying any `dilation_rate` value != 1 is\n",
      " |      incompatible with specifying any `strides` value != 1.\n",
      " |    groups: A positive integer specifying the number of groups in which the\n",
      " |      input is split along the channel axis. Each group is convolved\n",
      " |      separately with `filters / groups` filters. The output is the\n",
      " |      concatenation of all the `groups` results along the channel axis.\n",
      " |      Input channels and `filters` must both be divisible by `groups`.\n",
      " |    activation: Activation function to use.\n",
      " |      If you don't specify anything, no activation is applied\n",
      " |      (see `keras.activations`).\n",
      " |    use_bias: Boolean, whether the layer uses a bias vector.\n",
      " |    kernel_initializer: Initializer for the `kernel` weights matrix\n",
      " |      (see `keras.initializers`). Defaults to 'glorot_uniform'.\n",
      " |    bias_initializer: Initializer for the bias vector\n",
      " |      (see `keras.initializers`). Defaults to 'zeros'.\n",
      " |    kernel_regularizer: Regularizer function applied to\n",
      " |      the `kernel` weights matrix (see `keras.regularizers`).\n",
      " |    bias_regularizer: Regularizer function applied to the bias vector\n",
      " |      (see `keras.regularizers`).\n",
      " |    activity_regularizer: Regularizer function applied to\n",
      " |      the output of the layer (its \"activation\")\n",
      " |      (see `keras.regularizers`).\n",
      " |    kernel_constraint: Constraint function applied to the kernel matrix\n",
      " |      (see `keras.constraints`).\n",
      " |    bias_constraint: Constraint function applied to the bias vector\n",
      " |      (see `keras.constraints`).\n",
      " |  \n",
      " |  Input shape:\n",
      " |    3+D tensor with shape: `batch_shape + (steps, input_dim)`\n",
      " |  \n",
      " |  Output shape:\n",
      " |    3+D tensor with shape: `batch_shape + (new_steps, filters)`\n",
      " |      `steps` value might have changed due to padding or strides.\n",
      " |  \n",
      " |  Returns:\n",
      " |    A tensor of rank 3 representing\n",
      " |    `activation(conv1d(inputs, kernel) + bias)`.\n",
      " |  \n",
      " |  Raises:\n",
      " |    ValueError: when both `strides > 1` and `dilation_rate > 1`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Conv1D\n",
      " |      Conv\n",
      " |      keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      keras.utils.version_utils.LayerVersionSelector\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, filters, kernel_size, strides=1, padding='valid', data_format='channels_last', dilation_rate=1, groups=1, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Conv:\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (optional, for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      Note here that `call()` method in `tf.keras` is little bit different\n",
      " |      from `keras` API. In `keras` API, you can pass support masking for\n",
      " |      layers as additional arguments. Whereas `tf.keras` has `compute_mask()`\n",
      " |      method to support masking.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensor, or dict/list/tuple of input tensors.\n",
      " |          The first positional `inputs` argument is subject to special rules:\n",
      " |          - `inputs` must be explicitly passed. A layer cannot have zero\n",
      " |            arguments, and `inputs` cannot be provided via the default value\n",
      " |            of a keyword argument.\n",
      " |          - NumPy array or Python scalar values in `inputs` get cast as tensors.\n",
      " |          - Keras mask metadata is only collected from `inputs`.\n",
      " |          - Layers are built (`build(input_shape)` method)\n",
      " |            using shape info from `inputs` only.\n",
      " |          - `input_spec` compatibility is only checked against `inputs`.\n",
      " |          - Mixed precision input casting is only applied to `inputs`.\n",
      " |            If a layer has tensor arguments in `*args` or `**kwargs`, their\n",
      " |            casting behavior in mixed precision should be handled manually.\n",
      " |          - The SavedModel input specification is generated using `inputs` only.\n",
      " |          - Integration with various ecosystem packages like TFMOT, TFLite,\n",
      " |            TF.js, etc is only supported for `inputs` and not for tensors in\n",
      " |            positional and keyword arguments.\n",
      " |        *args: Additional positional arguments. May contain tensors, although\n",
      " |          this is not recommended, for the reasons above.\n",
      " |        **kwargs: Additional keyword arguments. May contain tensors, although\n",
      " |          this is not recommended, for the reasons above.\n",
      " |          The following optional keyword arguments are reserved:\n",
      " |          - `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          - `mask`: Boolean input mask. If the layer's `call()` method takes a\n",
      " |            `mask` argument, its default value will be set to the mask generated\n",
      " |            for `inputs` by the previous layer (if `input` did come from a layer\n",
      " |            that generated a corresponding mask, i.e. if it came from a Keras\n",
      " |            layer with masking support).\n",
      " |      \n",
      " |      Returns:\n",
      " |        A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      If the layer has not been built, this method will call `build` on the\n",
      " |      layer. This assumes that the layer will later be used with inputs that\n",
      " |      match the input shape provided here.\n",
      " |      \n",
      " |      Args:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  convolution_op(self, inputs, kernel)\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Note that `get_config()` does not guarantee to return a fresh copy of dict\n",
      " |      every time it is called. The callers should make a copy of the returned dict\n",
      " |      if they want to modify it.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Args:\n",
      " |        *args: Positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: Keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |        - If the layer is not built, the method will call `build`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |        RuntimeError: if `super().__init__()` was not called in the constructor.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, **kwargs)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(self, inputs):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Activity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      d = tf.keras.layers.Dense(10)\n",
      " |      x = d(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |            inputs - Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_metric(self, value, name=None, **kwargs)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      This method can be used inside the `call()` method of a subclassed layer\n",
      " |      or model.\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
      " |        def __init__(self):\n",
      " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
      " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
      " |      \n",
      " |        def call(self, inputs):\n",
      " |          self.add_metric(self.mean(inputs))\n",
      " |          self.add_metric(tf.reduce_sum(inputs), name='metric_2')\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any tensor passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      metrics become part of the model's topology and are tracked when you\n",
      " |      save the model via `save()`.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
      " |      Functional Model, as shown in the example below, is not supported. This is\n",
      " |      because we cannot trace the metric result tensor back to the model's inputs.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        name: String metric name.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |          `aggregation` - When the `value` tensor provided is not the result of\n",
      " |          calling a `keras.Metric` instance, it will be aggregated by default\n",
      " |          using a `keras.Metric.Mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Args:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregationV2.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The variable created.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  finalize_state(self)\n",
      " |      Finalizes the layers state after updating layer weights.\n",
      " |      \n",
      " |      This function can be subclassed in a layer and will be called after updating\n",
      " |      a layer weights. It can be overridden to finalize any additional layer state\n",
      " |      after a weight update.\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first input node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first output node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer, as NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      returns both trainable and non-trainable weight values associated with this\n",
      " |      layer as a list of NumPy arrays, which can in turn be used to load state\n",
      " |      into similarly parameterized layers.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel matrix\n",
      " |      and the bias vector. These can be used to set the weights of another\n",
      " |      `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of NumPy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      sets the weight values from numpy arrays. The weight values should be\n",
      " |      passed in the order they are created by the layer. Note that the layer's\n",
      " |      weights must be instantiated before calling this function, by calling\n",
      " |      the layer.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel matrix\n",
      " |      and the bias vector. These can be used to set the weights of another\n",
      " |      `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Args:\n",
      " |        weights: a list of NumPy arrays. The number\n",
      " |          of arrays and their shape must match\n",
      " |          number of the dimensions of the weights\n",
      " |          of the layer (i.e. it should match the\n",
      " |          output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If the provided weights list does not match the\n",
      " |          layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Args:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  compute_dtype\n",
      " |      The dtype of the layer's computations.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
      " |      the weights.\n",
      " |      \n",
      " |      Layers automatically cast their inputs to the compute dtype, which causes\n",
      " |      computations and the output to be in the compute dtype as well. This is done\n",
      " |      by the base Layer class in `Layer.__call__`, so you do not have to insert\n",
      " |      these casts if implementing your own layer.\n",
      " |      \n",
      " |      Layers often perform certain internal computations in higher precision when\n",
      " |      `compute_dtype` is float16 or bfloat16 for numeric stability. The output\n",
      " |      will still typically be float16 or bfloat16 in such cases.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The layer's compute dtype.\n",
      " |  \n",
      " |  dtype\n",
      " |      The dtype of the layer weights.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
      " |      dtype of the layer's computations.\n",
      " |  \n",
      " |  dtype_policy\n",
      " |      The dtype policy associated with this layer.\n",
      " |      \n",
      " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
      " |  \n",
      " |  dynamic\n",
      " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  losses\n",
      " |      List of losses added using the `add_loss()` API.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
      " |      ...   def call(self, inputs):\n",
      " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |      ...     return inputs\n",
      " |      >>> l = MyLayer()\n",
      " |      >>> l(np.ones((10, 1)))\n",
      " |      >>> l.losses\n",
      " |      [1.0]\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Activity regularization.\n",
      " |      >>> len(model.losses)\n",
      " |      0\n",
      " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      >>> len(model.losses)\n",
      " |      1\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
      " |      >>> x = d(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Weight regularization.\n",
      " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      >>> model.losses\n",
      " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  metrics\n",
      " |      List of metrics added using the `add_metric()` API.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      >>> input = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> d = tf.keras.layers.Dense(2)\n",
      " |      >>> output = d(input)\n",
      " |      >>> d.add_metric(tf.reduce_max(output), name='max')\n",
      " |      >>> d.add_metric(tf.reduce_min(output), name='min')\n",
      " |      >>> [m.name for m in d.metrics]\n",
      " |      ['max', 'min']\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of `Metric` objects.\n",
      " |  \n",
      " |  name\n",
      " |      Name of the layer (string), set in the constructor.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |      List of all non-trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Non-trainable weights are *not* updated during training. They are expected\n",
      " |      to be updated manually in `call()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of non-trainable variables.\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  trainable_weights\n",
      " |      List of all trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Trainable weights are updated via gradient descent during training.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of trainable variables.\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variable_dtype\n",
      " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
      " |      themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  input_spec\n",
      " |      `InputSpec` instance(s) describing the input format for this layer.\n",
      " |      \n",
      " |      When you create a layer subclass, you can set `self.input_spec` to enable\n",
      " |      the layer to run input compatibility checks when it is called.\n",
      " |      Consider a `Conv2D` layer: it can only be called on a single input tensor\n",
      " |      of rank 4. As such, you can set, in `__init__()`:\n",
      " |      \n",
      " |      ```python\n",
      " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
      " |      ```\n",
      " |      \n",
      " |      Now, if you try to call the layer on an input that isn't rank 4\n",
      " |      (for instance, an input of shape `(2,)`, it will raise a nicely-formatted\n",
      " |      error:\n",
      " |      \n",
      " |      ```\n",
      " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
      " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
      " |      ```\n",
      " |      \n",
      " |      Input checks that can be specified via `input_spec` include:\n",
      " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
      " |      - Shape\n",
      " |      - Rank (ndim)\n",
      " |      - Dtype\n",
      " |      \n",
      " |      For more information, see `tf.keras.layers.InputSpec`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  supports_masking\n",
      " |      Whether this layer supports computing a mask using `compute_mask`.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from keras.utils.version_utils.LayerVersionSelector:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Conv1D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87126ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>weekday</th>\n",
       "      <th>isRest</th>\n",
       "      <th>severity_num</th>\n",
       "      <th>priority_num</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002/9/23</th>\n",
       "      <td>206</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002/9/24</th>\n",
       "      <td>192</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002/9/25</th>\n",
       "      <td>245</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002/9/26</th>\n",
       "      <td>209</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002/9/27</th>\n",
       "      <td>225</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004/5/10</th>\n",
       "      <td>108</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004/5/11</th>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004/5/12</th>\n",
       "      <td>114</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004/5/13</th>\n",
       "      <td>97</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004/5/14</th>\n",
       "      <td>85</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           number  weekday  isRest  severity_num  priority_num  category\n",
       "time                                                                    \n",
       "2002/9/23     206        2       0            18            13         3\n",
       "2002/9/24     192        3       0            29            18         3\n",
       "2002/9/25     245        4       0            34            16         3\n",
       "2002/9/26     209        5       0            18            20         3\n",
       "2002/9/27     225        6       0            30            27         3\n",
       "...           ...      ...     ...           ...           ...       ...\n",
       "2004/5/10     108        2       0            11             6         2\n",
       "2004/5/11     110        3       0            18             8         2\n",
       "2004/5/12     114        4       0            15             8         2\n",
       "2004/5/13      97        5       0            17             3         1\n",
       "2004/5/14      85        6       0             8             3         1\n",
       "\n",
       "[600 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/da1.csv',index_col='time')\n",
    "data = data.iloc[:,[0,1,2,5,6,7]]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6792b61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(data.iloc[:,[0]].values)\n",
    "# dataset = scaler.fit_transform(data.iloc[:,[0,1,2,3,4]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f5da822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67672414],\n",
       "       [0.61637931],\n",
       "       [0.84482759],\n",
       "       [0.68965517],\n",
       "       [0.75862069],\n",
       "       [0.45258621],\n",
       "       [0.43103448],\n",
       "       [0.75      ],\n",
       "       [0.72844828],\n",
       "       [0.70689655],\n",
       "       [0.84051724],\n",
       "       [0.64655172],\n",
       "       [0.25      ],\n",
       "       [0.47844828],\n",
       "       [0.68965517],\n",
       "       [0.71982759],\n",
       "       [0.82327586],\n",
       "       [0.76724138],\n",
       "       [0.60344828],\n",
       "       [0.24137931],\n",
       "       [0.2887931 ],\n",
       "       [0.65086207],\n",
       "       [0.63362069],\n",
       "       [0.71982759],\n",
       "       [1.        ],\n",
       "       [0.79741379],\n",
       "       [0.44396552],\n",
       "       [0.34913793],\n",
       "       [0.7887931 ],\n",
       "       [0.77586207],\n",
       "       [0.86206897],\n",
       "       [0.75431034],\n",
       "       [0.64224138],\n",
       "       [0.31465517],\n",
       "       [0.21982759],\n",
       "       [0.52586207],\n",
       "       [0.61206897],\n",
       "       [0.73706897],\n",
       "       [0.68534483],\n",
       "       [0.48706897],\n",
       "       [0.27155172],\n",
       "       [0.2887931 ],\n",
       "       [0.41810345],\n",
       "       [0.67672414],\n",
       "       [0.68965517],\n",
       "       [0.72844828],\n",
       "       [0.38793103],\n",
       "       [0.49568966],\n",
       "       [0.3362069 ],\n",
       "       [0.61206897],\n",
       "       [0.76293103],\n",
       "       [0.63362069],\n",
       "       [0.62068966],\n",
       "       [0.56034483],\n",
       "       [0.23706897],\n",
       "       [0.3362069 ],\n",
       "       [0.59913793],\n",
       "       [0.52586207],\n",
       "       [0.64655172],\n",
       "       [0.55603448],\n",
       "       [0.53017241],\n",
       "       [0.29310345],\n",
       "       [0.29310345],\n",
       "       [0.37931034],\n",
       "       [0.60344828],\n",
       "       [0.96551724],\n",
       "       [0.53017241],\n",
       "       [0.52155172],\n",
       "       [0.20258621],\n",
       "       [0.21551724],\n",
       "       [0.5862069 ],\n",
       "       [0.95258621],\n",
       "       [0.90086207],\n",
       "       [0.61206897],\n",
       "       [0.56034483],\n",
       "       [0.39224138],\n",
       "       [0.60344828],\n",
       "       [0.78017241],\n",
       "       [0.61637931],\n",
       "       [0.55172414],\n",
       "       [0.57758621],\n",
       "       [0.49568966],\n",
       "       [0.29310345],\n",
       "       [0.32758621],\n",
       "       [0.64655172],\n",
       "       [0.59913793],\n",
       "       [0.49137931],\n",
       "       [0.34482759],\n",
       "       [0.3362069 ],\n",
       "       [0.11206897],\n",
       "       [0.15948276],\n",
       "       [0.23275862],\n",
       "       [0.2112069 ],\n",
       "       [0.06465517],\n",
       "       [0.13362069],\n",
       "       [0.18534483],\n",
       "       [0.14224138],\n",
       "       [0.09051724],\n",
       "       [0.26724138],\n",
       "       [0.18103448],\n",
       "       [0.19827586],\n",
       "       [0.34913793],\n",
       "       [0.26293103],\n",
       "       [0.20258621],\n",
       "       [0.28448276],\n",
       "       [0.47844828],\n",
       "       [0.33189655],\n",
       "       [0.40086207],\n",
       "       [0.55172414],\n",
       "       [0.48706897],\n",
       "       [0.28448276],\n",
       "       [0.26293103],\n",
       "       [0.40948276],\n",
       "       [0.45689655],\n",
       "       [0.26724138],\n",
       "       [0.42672414],\n",
       "       [0.44396552],\n",
       "       [0.14655172],\n",
       "       [0.22844828],\n",
       "       [0.29310345],\n",
       "       [0.58189655],\n",
       "       [0.68103448],\n",
       "       [0.5       ],\n",
       "       [0.43534483],\n",
       "       [0.13793103],\n",
       "       [0.21551724],\n",
       "       [0.48706897],\n",
       "       [0.43965517],\n",
       "       [0.63362069],\n",
       "       [0.46551724],\n",
       "       [0.30603448],\n",
       "       [0.11637931],\n",
       "       [0.17241379],\n",
       "       [0.39655172],\n",
       "       [0.31034483],\n",
       "       [0.32327586],\n",
       "       [0.30172414],\n",
       "       [0.49568966],\n",
       "       [0.11637931],\n",
       "       [0.11206897],\n",
       "       [0.37931034],\n",
       "       [0.67241379],\n",
       "       [0.73275862],\n",
       "       [0.67672414],\n",
       "       [0.4612069 ],\n",
       "       [0.15517241],\n",
       "       [0.25862069],\n",
       "       [0.5387931 ],\n",
       "       [0.50862069],\n",
       "       [0.59051724],\n",
       "       [0.53448276],\n",
       "       [0.31465517],\n",
       "       [0.2112069 ],\n",
       "       [0.22413793],\n",
       "       [0.52586207],\n",
       "       [0.59482759],\n",
       "       [0.40517241],\n",
       "       [0.625     ],\n",
       "       [0.40517241],\n",
       "       [0.12068966],\n",
       "       [0.25431034],\n",
       "       [0.50431034],\n",
       "       [0.36206897],\n",
       "       [0.40948276],\n",
       "       [0.43534483],\n",
       "       [0.34913793],\n",
       "       [0.20689655],\n",
       "       [0.35344828],\n",
       "       [0.49137931],\n",
       "       [0.60775862],\n",
       "       [0.49137931],\n",
       "       [0.48275862],\n",
       "       [0.57758621],\n",
       "       [0.39655172],\n",
       "       [0.30603448],\n",
       "       [0.59482759],\n",
       "       [0.69827586],\n",
       "       [0.55603448],\n",
       "       [0.61637931],\n",
       "       [0.5       ],\n",
       "       [0.29741379],\n",
       "       [0.18534483],\n",
       "       [0.52155172],\n",
       "       [0.50862069],\n",
       "       [0.4612069 ],\n",
       "       [0.62068966],\n",
       "       [0.46551724],\n",
       "       [0.09482759],\n",
       "       [0.15086207],\n",
       "       [0.5       ],\n",
       "       [0.45689655],\n",
       "       [0.64655172],\n",
       "       [0.56034483],\n",
       "       [0.43534483],\n",
       "       [0.29310345],\n",
       "       [0.20689655],\n",
       "       [0.52155172],\n",
       "       [0.43965517],\n",
       "       [0.42241379],\n",
       "       [0.51724138],\n",
       "       [0.38793103],\n",
       "       [0.14224138],\n",
       "       [0.13793103],\n",
       "       [0.45258621],\n",
       "       [0.43965517],\n",
       "       [0.42241379],\n",
       "       [0.38793103],\n",
       "       [0.27586207],\n",
       "       [0.06896552],\n",
       "       [0.09051724],\n",
       "       [0.23706897],\n",
       "       [0.4137931 ],\n",
       "       [0.4137931 ],\n",
       "       [0.34913793],\n",
       "       [0.43965517],\n",
       "       [0.25      ],\n",
       "       [0.14224138],\n",
       "       [0.34913793],\n",
       "       [0.34482759],\n",
       "       [0.40517241],\n",
       "       [0.36637931],\n",
       "       [0.35775862],\n",
       "       [0.09482759],\n",
       "       [0.11206897],\n",
       "       [0.375     ],\n",
       "       [0.32327586],\n",
       "       [0.39655172],\n",
       "       [0.41810345],\n",
       "       [0.45258621],\n",
       "       [0.12068966],\n",
       "       [0.10775862],\n",
       "       [0.55172414],\n",
       "       [0.40517241],\n",
       "       [0.50862069],\n",
       "       [0.32758621],\n",
       "       [0.34051724],\n",
       "       [0.22413793],\n",
       "       [0.18965517],\n",
       "       [0.51293103],\n",
       "       [0.47413793],\n",
       "       [0.47413793],\n",
       "       [0.35775862],\n",
       "       [0.30603448],\n",
       "       [0.10344828],\n",
       "       [0.09051724],\n",
       "       [0.19827586],\n",
       "       [0.31465517],\n",
       "       [0.37068966],\n",
       "       [0.34482759],\n",
       "       [0.43103448],\n",
       "       [0.20689655],\n",
       "       [0.22413793],\n",
       "       [0.35775862],\n",
       "       [0.42672414],\n",
       "       [0.43534483],\n",
       "       [0.36637931],\n",
       "       [0.14655172],\n",
       "       [0.15517241],\n",
       "       [0.10344828],\n",
       "       [0.31034483],\n",
       "       [0.36206897],\n",
       "       [0.28017241],\n",
       "       [0.32758621],\n",
       "       [0.26293103],\n",
       "       [0.15086207],\n",
       "       [0.06034483],\n",
       "       [0.29741379],\n",
       "       [0.27155172],\n",
       "       [0.47844828],\n",
       "       [0.44396552],\n",
       "       [0.34482759],\n",
       "       [0.09051724],\n",
       "       [0.16810345],\n",
       "       [0.32327586],\n",
       "       [0.33189655],\n",
       "       [0.4137931 ],\n",
       "       [0.3362069 ],\n",
       "       [0.26724138],\n",
       "       [0.00431034],\n",
       "       [0.02586207],\n",
       "       [0.31896552],\n",
       "       [0.56034483],\n",
       "       [0.47844828],\n",
       "       [0.33189655],\n",
       "       [0.18103448],\n",
       "       [0.06896552],\n",
       "       [0.19396552],\n",
       "       [0.21982759],\n",
       "       [0.27586207],\n",
       "       [0.31034483],\n",
       "       [0.30603448],\n",
       "       [0.28448276],\n",
       "       [0.06465517],\n",
       "       [0.09482759],\n",
       "       [0.21982759],\n",
       "       [0.23275862],\n",
       "       [0.22413793],\n",
       "       [0.27586207],\n",
       "       [0.22844828],\n",
       "       [0.04741379],\n",
       "       [0.06896552],\n",
       "       [0.17241379],\n",
       "       [0.32758621],\n",
       "       [0.45689655],\n",
       "       [0.49137931],\n",
       "       [0.37068966],\n",
       "       [0.10775862],\n",
       "       [0.21551724],\n",
       "       [0.29310345],\n",
       "       [0.45689655],\n",
       "       [0.48275862],\n",
       "       [0.41810345],\n",
       "       [0.375     ],\n",
       "       [0.00862069],\n",
       "       [0.16810345],\n",
       "       [0.26724138],\n",
       "       [0.34051724],\n",
       "       [0.4137931 ],\n",
       "       [0.26724138],\n",
       "       [0.3362069 ],\n",
       "       [0.07758621],\n",
       "       [0.14224138],\n",
       "       [0.3362069 ],\n",
       "       [0.30603448],\n",
       "       [0.29741379],\n",
       "       [0.24137931],\n",
       "       [0.25431034],\n",
       "       [0.15086207],\n",
       "       [0.15517241],\n",
       "       [0.31034483],\n",
       "       [0.24568966],\n",
       "       [0.22844828],\n",
       "       [0.32758621],\n",
       "       [0.18534483],\n",
       "       [0.09051724],\n",
       "       [0.05603448],\n",
       "       [0.23706897],\n",
       "       [0.28448276],\n",
       "       [0.39224138],\n",
       "       [0.39655172],\n",
       "       [0.22413793],\n",
       "       [0.06465517],\n",
       "       [0.15086207],\n",
       "       [0.20689655],\n",
       "       [0.27155172],\n",
       "       [0.25431034],\n",
       "       [0.27155172],\n",
       "       [0.25431034],\n",
       "       [0.06896552],\n",
       "       [0.06034483],\n",
       "       [0.24568966],\n",
       "       [0.15948276],\n",
       "       [0.18965517],\n",
       "       [0.25431034],\n",
       "       [0.1637931 ],\n",
       "       [0.13793103],\n",
       "       [0.06034483],\n",
       "       [0.21551724],\n",
       "       [0.18534483],\n",
       "       [0.25      ],\n",
       "       [0.34482759],\n",
       "       [0.21982759],\n",
       "       [0.09482759],\n",
       "       [0.15948276],\n",
       "       [0.23706897],\n",
       "       [0.28017241],\n",
       "       [0.20258621],\n",
       "       [0.20258621],\n",
       "       [0.20689655],\n",
       "       [0.18534483],\n",
       "       [0.18965517],\n",
       "       [0.375     ],\n",
       "       [0.29310345],\n",
       "       [0.30172414],\n",
       "       [0.25      ],\n",
       "       [0.1637931 ],\n",
       "       [0.05603448],\n",
       "       [0.19827586],\n",
       "       [0.26293103],\n",
       "       [0.18965517],\n",
       "       [0.29741379],\n",
       "       [0.24568966],\n",
       "       [0.13362069],\n",
       "       [0.03017241],\n",
       "       [0.11206897],\n",
       "       [0.20258621],\n",
       "       [0.36637931],\n",
       "       [0.53448276],\n",
       "       [0.56465517],\n",
       "       [0.53017241],\n",
       "       [0.17241379],\n",
       "       [0.19827586],\n",
       "       [0.3362069 ],\n",
       "       [0.40948276],\n",
       "       [0.46982759],\n",
       "       [0.45689655],\n",
       "       [0.30172414],\n",
       "       [0.09482759],\n",
       "       [0.25      ],\n",
       "       [0.28448276],\n",
       "       [0.24137931],\n",
       "       [0.38793103],\n",
       "       [0.22413793],\n",
       "       [0.17672414],\n",
       "       [0.13793103],\n",
       "       [0.13362069],\n",
       "       [0.42241379],\n",
       "       [0.1637931 ],\n",
       "       [0.23275862],\n",
       "       [0.23275862],\n",
       "       [0.19396552],\n",
       "       [0.03017241],\n",
       "       [0.15517241],\n",
       "       [0.2112069 ],\n",
       "       [0.31465517],\n",
       "       [0.31034483],\n",
       "       [0.31896552],\n",
       "       [0.2887931 ],\n",
       "       [0.14224138],\n",
       "       [0.12931034],\n",
       "       [0.28448276],\n",
       "       [0.28017241],\n",
       "       [0.32758621],\n",
       "       [0.19827586],\n",
       "       [0.20258621],\n",
       "       [0.03017241],\n",
       "       [0.11206897],\n",
       "       [0.10344828],\n",
       "       [0.25862069],\n",
       "       [0.18103448],\n",
       "       [0.11206897],\n",
       "       [0.07327586],\n",
       "       [0.        ],\n",
       "       [0.02586207],\n",
       "       [0.24137931],\n",
       "       [0.14655172],\n",
       "       [0.19396552],\n",
       "       [0.24568966],\n",
       "       [0.14224138],\n",
       "       [0.10344828],\n",
       "       [0.20258621],\n",
       "       [0.27155172],\n",
       "       [0.27586207],\n",
       "       [0.27586207],\n",
       "       [0.30172414],\n",
       "       [0.24137931],\n",
       "       [0.11637931],\n",
       "       [0.18534483],\n",
       "       [0.25862069],\n",
       "       [0.27586207],\n",
       "       [0.2112069 ],\n",
       "       [0.16810345],\n",
       "       [0.17672414],\n",
       "       [0.0387931 ],\n",
       "       [0.07758621],\n",
       "       [0.17672414],\n",
       "       [0.09482759],\n",
       "       [0.06896552],\n",
       "       [0.05172414],\n",
       "       [0.0862069 ],\n",
       "       [0.00862069],\n",
       "       [0.07327586],\n",
       "       [0.13362069],\n",
       "       [0.06034483],\n",
       "       [0.04310345],\n",
       "       [0.04310345],\n",
       "       [0.0387931 ],\n",
       "       [0.09051724],\n",
       "       [0.14224138],\n",
       "       [0.13793103],\n",
       "       [0.22413793],\n",
       "       [0.17241379],\n",
       "       [0.27155172],\n",
       "       [0.09482759],\n",
       "       [0.04310345],\n",
       "       [0.0387931 ],\n",
       "       [0.2112069 ],\n",
       "       [0.18965517],\n",
       "       [0.21551724],\n",
       "       [0.25431034],\n",
       "       [0.48275862],\n",
       "       [0.23706897],\n",
       "       [0.21551724],\n",
       "       [0.33189655],\n",
       "       [0.36206897],\n",
       "       [0.19827586],\n",
       "       [0.29741379],\n",
       "       [0.26293103],\n",
       "       [0.10344828],\n",
       "       [0.11206897],\n",
       "       [0.25      ],\n",
       "       [0.29741379],\n",
       "       [0.26724138],\n",
       "       [0.31465517],\n",
       "       [0.18103448],\n",
       "       [0.04310345],\n",
       "       [0.03017241],\n",
       "       [0.21982759],\n",
       "       [0.16810345],\n",
       "       [0.2112069 ],\n",
       "       [0.29741379],\n",
       "       [0.16810345],\n",
       "       [0.06896552],\n",
       "       [0.14655172],\n",
       "       [0.43965517],\n",
       "       [0.47844828],\n",
       "       [0.60775862],\n",
       "       [0.41810345],\n",
       "       [0.4137931 ],\n",
       "       [0.27155172],\n",
       "       [0.21551724],\n",
       "       [0.29741379],\n",
       "       [0.38362069],\n",
       "       [0.26724138],\n",
       "       [0.35775862],\n",
       "       [0.27155172],\n",
       "       [0.14655172],\n",
       "       [0.125     ],\n",
       "       [0.32327586],\n",
       "       [0.36637931],\n",
       "       [0.38362069],\n",
       "       [0.35775862],\n",
       "       [0.3362069 ],\n",
       "       [0.15517241],\n",
       "       [0.09051724],\n",
       "       [0.18965517],\n",
       "       [0.34051724],\n",
       "       [0.36206897],\n",
       "       [0.20258621],\n",
       "       [0.30603448],\n",
       "       [0.07327586],\n",
       "       [0.05172414],\n",
       "       [0.2887931 ],\n",
       "       [0.16810345],\n",
       "       [0.30603448],\n",
       "       [0.375     ],\n",
       "       [0.25      ],\n",
       "       [0.06896552],\n",
       "       [0.16810345],\n",
       "       [0.31896552],\n",
       "       [0.36206897],\n",
       "       [0.27155172],\n",
       "       [0.20689655],\n",
       "       [0.26293103],\n",
       "       [0.12068966],\n",
       "       [0.16810345],\n",
       "       [0.27586207],\n",
       "       [0.31465517],\n",
       "       [0.35344828],\n",
       "       [0.39655172],\n",
       "       [0.37931034],\n",
       "       [0.13362069],\n",
       "       [0.14655172],\n",
       "       [0.25      ],\n",
       "       [0.21551724],\n",
       "       [0.14224138],\n",
       "       [0.125     ],\n",
       "       [0.14224138],\n",
       "       [0.12068966],\n",
       "       [0.15517241],\n",
       "       [0.33189655],\n",
       "       [0.11206897],\n",
       "       [0.31465517],\n",
       "       [0.13793103],\n",
       "       [0.13362069],\n",
       "       [0.08189655],\n",
       "       [0.13793103],\n",
       "       [0.11637931],\n",
       "       [0.25      ],\n",
       "       [0.23706897],\n",
       "       [0.24568966],\n",
       "       [0.16810345],\n",
       "       [0.11637931],\n",
       "       [0.19396552],\n",
       "       [0.31896552],\n",
       "       [0.27586207],\n",
       "       [0.27155172],\n",
       "       [0.35775862],\n",
       "       [0.32327586],\n",
       "       [0.10344828],\n",
       "       [0.21982759],\n",
       "       [0.31465517],\n",
       "       [0.12068966],\n",
       "       [0.34913793],\n",
       "       [0.25      ],\n",
       "       [0.20689655],\n",
       "       [0.08189655],\n",
       "       [0.09913793],\n",
       "       [0.36206897],\n",
       "       [0.31465517],\n",
       "       [0.28017241],\n",
       "       [0.40517241],\n",
       "       [0.18534483],\n",
       "       [0.15086207],\n",
       "       [0.12931034],\n",
       "       [0.25431034],\n",
       "       [0.26293103],\n",
       "       [0.28017241],\n",
       "       [0.20689655],\n",
       "       [0.15517241]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fd87bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data,dataset,lookback):\n",
    "    dataX,dataY = [],[]\n",
    "    for i in range(len(data) - lookback):\n",
    "        a = dataset[i:i+lookback,[0,1,2,3,4]]\n",
    "#         a = dataset[i:i+lookback,[0,1,2]]\n",
    "#         print(a)\n",
    "        dataX.append(a)\n",
    "        dataY.append(data.iloc[i+lookback,[5]])\n",
    "    return np.array(dataX),np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "699446e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data,dataset,lookback):\n",
    "    dataX,dataY = [],[]\n",
    "    for i in range(len(data) - lookback):\n",
    "#         a = dataset[i:i+lookback,[0,1,2,3,4]]\n",
    "        a = dataset[i:i+lookback,[0]]\n",
    "#         print(a)\n",
    "        dataX.append(a)\n",
    "        dataY.append(data.iloc[i+lookback,[5]])\n",
    "    return np.array(dataX),np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5bdc5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 7\n",
    "dataX,dataY = create_dataset(data,dataset,lookback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bba33ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((593, 7, 1), (593, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataX.shape,dataY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "341e32d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bc289e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将category列进行one-hot编码\n",
    "one_hots = to_categorical(dataY-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17b980fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(593, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hots.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8b428cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainX,testX,trainY,testY = train_test_split(dataX,one_hots,test_size=0.20, random_state=1)\n",
    "trainX,testX,trainY,testY = train_test_split(dataX,one_hots,test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1225e5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((474, 7, 1), (119, 7, 1), (474, 3), (119, 3))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape,testX.shape,trainY.shape,testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0597b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a305a99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(trainX.shape[1],trainX.shape[2]))\n",
    "y = Conv1D(16, 3, activation='relu')(inputs)\n",
    "z = Conv1D(16, 3, activation='relu')(y)\n",
    "t = Conv1D(16, 3, activation='relu')(z)\n",
    "o = Flatten()(t)\n",
    "# o = Dense(32, activation='relu')(o)\n",
    "outputs = Dense(3, activation = 'softmax')(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5c16da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs = inputs,outputs = outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b20e862",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edd64780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 7, 1)]            0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 5, 16)             64        \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 3, 16)             784       \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 1, 16)             784       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,683\n",
      "Trainable params: 1,683\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f832c2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 - 0s - loss: 1.1050 - accuracy: 0.3034 - val_loss: 1.1128 - val_accuracy: 0.3474 - 387ms/epoch - 129ms/step\n",
      "Epoch 2/100\n",
      "3/3 - 0s - loss: 1.1027 - accuracy: 0.3272 - val_loss: 1.1095 - val_accuracy: 0.3895 - 16ms/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "3/3 - 0s - loss: 1.1011 - accuracy: 0.3509 - val_loss: 1.1066 - val_accuracy: 0.3684 - 16ms/epoch - 5ms/step\n",
      "Epoch 4/100\n",
      "3/3 - 0s - loss: 1.0994 - accuracy: 0.3799 - val_loss: 1.1038 - val_accuracy: 0.3474 - 17ms/epoch - 6ms/step\n",
      "Epoch 5/100\n",
      "3/3 - 0s - loss: 1.0977 - accuracy: 0.3720 - val_loss: 1.1010 - val_accuracy: 0.3474 - 16ms/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "3/3 - 0s - loss: 1.0959 - accuracy: 0.3720 - val_loss: 1.0984 - val_accuracy: 0.3474 - 17ms/epoch - 6ms/step\n",
      "Epoch 7/100\n",
      "3/3 - 0s - loss: 1.0943 - accuracy: 0.3826 - val_loss: 1.0959 - val_accuracy: 0.3684 - 17ms/epoch - 6ms/step\n",
      "Epoch 8/100\n",
      "3/3 - 0s - loss: 1.0926 - accuracy: 0.4011 - val_loss: 1.0932 - val_accuracy: 0.3684 - 16ms/epoch - 5ms/step\n",
      "Epoch 9/100\n",
      "3/3 - 0s - loss: 1.0908 - accuracy: 0.3984 - val_loss: 1.0905 - val_accuracy: 0.3789 - 16ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "3/3 - 0s - loss: 1.0889 - accuracy: 0.3984 - val_loss: 1.0879 - val_accuracy: 0.3895 - 16ms/epoch - 5ms/step\n",
      "Epoch 11/100\n",
      "3/3 - 0s - loss: 1.0872 - accuracy: 0.3958 - val_loss: 1.0854 - val_accuracy: 0.3895 - 16ms/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "3/3 - 0s - loss: 1.0853 - accuracy: 0.4037 - val_loss: 1.0830 - val_accuracy: 0.3895 - 16ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "3/3 - 0s - loss: 1.0835 - accuracy: 0.3984 - val_loss: 1.0804 - val_accuracy: 0.3789 - 16ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "3/3 - 0s - loss: 1.0816 - accuracy: 0.3984 - val_loss: 1.0775 - val_accuracy: 0.4105 - 16ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "3/3 - 0s - loss: 1.0795 - accuracy: 0.4090 - val_loss: 1.0747 - val_accuracy: 0.4316 - 16ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "3/3 - 0s - loss: 1.0775 - accuracy: 0.4248 - val_loss: 1.0715 - val_accuracy: 0.4632 - 17ms/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "3/3 - 0s - loss: 1.0751 - accuracy: 0.4301 - val_loss: 1.0681 - val_accuracy: 0.4842 - 17ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "3/3 - 0s - loss: 1.0728 - accuracy: 0.4433 - val_loss: 1.0643 - val_accuracy: 0.4947 - 17ms/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "3/3 - 0s - loss: 1.0701 - accuracy: 0.4538 - val_loss: 1.0604 - val_accuracy: 0.4947 - 18ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "3/3 - 0s - loss: 1.0673 - accuracy: 0.4565 - val_loss: 1.0565 - val_accuracy: 0.4947 - 17ms/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "3/3 - 0s - loss: 1.0641 - accuracy: 0.4749 - val_loss: 1.0520 - val_accuracy: 0.5053 - 18ms/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "3/3 - 0s - loss: 1.0610 - accuracy: 0.4960 - val_loss: 1.0467 - val_accuracy: 0.5579 - 16ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "3/3 - 0s - loss: 1.0574 - accuracy: 0.5145 - val_loss: 1.0411 - val_accuracy: 0.5684 - 15ms/epoch - 5ms/step\n",
      "Epoch 24/100\n",
      "3/3 - 0s - loss: 1.0534 - accuracy: 0.5330 - val_loss: 1.0347 - val_accuracy: 0.5789 - 16ms/epoch - 5ms/step\n",
      "Epoch 25/100\n",
      "3/3 - 0s - loss: 1.0489 - accuracy: 0.5383 - val_loss: 1.0277 - val_accuracy: 0.5895 - 17ms/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "3/3 - 0s - loss: 1.0439 - accuracy: 0.5303 - val_loss: 1.0198 - val_accuracy: 0.6000 - 17ms/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "3/3 - 0s - loss: 1.0386 - accuracy: 0.5435 - val_loss: 1.0110 - val_accuracy: 0.6000 - 16ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "3/3 - 0s - loss: 1.0324 - accuracy: 0.5462 - val_loss: 1.0016 - val_accuracy: 0.6000 - 17ms/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "3/3 - 0s - loss: 1.0258 - accuracy: 0.5541 - val_loss: 0.9912 - val_accuracy: 0.6000 - 16ms/epoch - 5ms/step\n",
      "Epoch 30/100\n",
      "3/3 - 0s - loss: 1.0189 - accuracy: 0.5541 - val_loss: 0.9809 - val_accuracy: 0.6000 - 17ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "3/3 - 0s - loss: 1.0109 - accuracy: 0.5541 - val_loss: 0.9694 - val_accuracy: 0.6000 - 16ms/epoch - 5ms/step\n",
      "Epoch 32/100\n",
      "3/3 - 0s - loss: 1.0035 - accuracy: 0.5646 - val_loss: 0.9566 - val_accuracy: 0.6105 - 16ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "3/3 - 0s - loss: 0.9948 - accuracy: 0.5831 - val_loss: 0.9445 - val_accuracy: 0.6105 - 17ms/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "3/3 - 0s - loss: 0.9865 - accuracy: 0.5884 - val_loss: 0.9309 - val_accuracy: 0.6105 - 16ms/epoch - 5ms/step\n",
      "Epoch 35/100\n",
      "3/3 - 0s - loss: 0.9774 - accuracy: 0.5884 - val_loss: 0.9180 - val_accuracy: 0.6000 - 17ms/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "3/3 - 0s - loss: 0.9694 - accuracy: 0.5937 - val_loss: 0.9039 - val_accuracy: 0.6105 - 17ms/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "3/3 - 0s - loss: 0.9602 - accuracy: 0.5937 - val_loss: 0.8940 - val_accuracy: 0.6105 - 16ms/epoch - 5ms/step\n",
      "Epoch 38/100\n",
      "3/3 - 0s - loss: 0.9504 - accuracy: 0.6042 - val_loss: 0.8801 - val_accuracy: 0.6000 - 17ms/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "3/3 - 0s - loss: 0.9410 - accuracy: 0.5937 - val_loss: 0.8662 - val_accuracy: 0.6000 - 16ms/epoch - 5ms/step\n",
      "Epoch 40/100\n",
      "3/3 - 0s - loss: 0.9326 - accuracy: 0.6095 - val_loss: 0.8539 - val_accuracy: 0.6105 - 17ms/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "3/3 - 0s - loss: 0.9235 - accuracy: 0.6069 - val_loss: 0.8435 - val_accuracy: 0.6105 - 16ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "3/3 - 0s - loss: 0.9143 - accuracy: 0.6069 - val_loss: 0.8322 - val_accuracy: 0.6105 - 17ms/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "3/3 - 0s - loss: 0.9058 - accuracy: 0.6095 - val_loss: 0.8179 - val_accuracy: 0.6000 - 17ms/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "3/3 - 0s - loss: 0.8964 - accuracy: 0.6069 - val_loss: 0.8075 - val_accuracy: 0.6000 - 16ms/epoch - 5ms/step\n",
      "Epoch 45/100\n",
      "3/3 - 0s - loss: 0.8891 - accuracy: 0.6042 - val_loss: 0.8004 - val_accuracy: 0.6000 - 16ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "3/3 - 0s - loss: 0.8800 - accuracy: 0.6227 - val_loss: 0.7878 - val_accuracy: 0.5895 - 16ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "3/3 - 0s - loss: 0.8738 - accuracy: 0.5910 - val_loss: 0.7770 - val_accuracy: 0.6105 - 17ms/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "3/3 - 0s - loss: 0.8637 - accuracy: 0.6042 - val_loss: 0.7711 - val_accuracy: 0.6105 - 16ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "3/3 - 0s - loss: 0.8578 - accuracy: 0.6148 - val_loss: 0.7666 - val_accuracy: 0.5789 - 17ms/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "3/3 - 0s - loss: 0.8524 - accuracy: 0.6095 - val_loss: 0.7534 - val_accuracy: 0.6211 - 17ms/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "3/3 - 0s - loss: 0.8440 - accuracy: 0.6121 - val_loss: 0.7465 - val_accuracy: 0.6211 - 18ms/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "3/3 - 0s - loss: 0.8364 - accuracy: 0.6121 - val_loss: 0.7420 - val_accuracy: 0.6211 - 19ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "3/3 - 0s - loss: 0.8309 - accuracy: 0.6121 - val_loss: 0.7384 - val_accuracy: 0.6211 - 18ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "3/3 - 0s - loss: 0.8256 - accuracy: 0.6201 - val_loss: 0.7289 - val_accuracy: 0.6526 - 18ms/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "3/3 - 0s - loss: 0.8197 - accuracy: 0.6174 - val_loss: 0.7214 - val_accuracy: 0.6316 - 19ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "3/3 - 0s - loss: 0.8146 - accuracy: 0.6121 - val_loss: 0.7175 - val_accuracy: 0.6421 - 18ms/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "3/3 - 0s - loss: 0.8094 - accuracy: 0.6174 - val_loss: 0.7121 - val_accuracy: 0.6421 - 19ms/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "3/3 - 0s - loss: 0.8055 - accuracy: 0.6148 - val_loss: 0.7096 - val_accuracy: 0.6421 - 17ms/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "3/3 - 0s - loss: 0.7992 - accuracy: 0.6174 - val_loss: 0.7020 - val_accuracy: 0.6632 - 17ms/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "3/3 - 0s - loss: 0.7950 - accuracy: 0.6280 - val_loss: 0.6964 - val_accuracy: 0.6632 - 17ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "3/3 - 0s - loss: 0.7921 - accuracy: 0.6227 - val_loss: 0.6926 - val_accuracy: 0.6632 - 17ms/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "3/3 - 0s - loss: 0.7869 - accuracy: 0.6332 - val_loss: 0.6897 - val_accuracy: 0.6737 - 17ms/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "3/3 - 0s - loss: 0.7835 - accuracy: 0.6332 - val_loss: 0.6865 - val_accuracy: 0.6737 - 18ms/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "3/3 - 0s - loss: 0.7801 - accuracy: 0.6359 - val_loss: 0.6817 - val_accuracy: 0.6842 - 17ms/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "3/3 - 0s - loss: 0.7763 - accuracy: 0.6253 - val_loss: 0.6821 - val_accuracy: 0.6632 - 18ms/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "3/3 - 0s - loss: 0.7728 - accuracy: 0.6385 - val_loss: 0.6760 - val_accuracy: 0.6842 - 17ms/epoch - 6ms/step\n",
      "Epoch 67/100\n",
      "3/3 - 0s - loss: 0.7691 - accuracy: 0.6332 - val_loss: 0.6720 - val_accuracy: 0.6947 - 17ms/epoch - 6ms/step\n",
      "Epoch 68/100\n",
      "3/3 - 0s - loss: 0.7671 - accuracy: 0.6332 - val_loss: 0.6698 - val_accuracy: 0.6947 - 17ms/epoch - 6ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100\n",
      "3/3 - 0s - loss: 0.7648 - accuracy: 0.6227 - val_loss: 0.6651 - val_accuracy: 0.6947 - 16ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "3/3 - 0s - loss: 0.7608 - accuracy: 0.6385 - val_loss: 0.6681 - val_accuracy: 0.6947 - 17ms/epoch - 6ms/step\n",
      "Epoch 71/100\n",
      "3/3 - 0s - loss: 0.7577 - accuracy: 0.6438 - val_loss: 0.6646 - val_accuracy: 0.6842 - 16ms/epoch - 5ms/step\n",
      "Epoch 72/100\n",
      "3/3 - 0s - loss: 0.7552 - accuracy: 0.6385 - val_loss: 0.6597 - val_accuracy: 0.6947 - 16ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "3/3 - 0s - loss: 0.7543 - accuracy: 0.6385 - val_loss: 0.6612 - val_accuracy: 0.6842 - 16ms/epoch - 5ms/step\n",
      "Epoch 74/100\n",
      "3/3 - 0s - loss: 0.7503 - accuracy: 0.6438 - val_loss: 0.6561 - val_accuracy: 0.6947 - 16ms/epoch - 5ms/step\n",
      "Epoch 75/100\n",
      "3/3 - 0s - loss: 0.7473 - accuracy: 0.6464 - val_loss: 0.6561 - val_accuracy: 0.6947 - 16ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "3/3 - 0s - loss: 0.7472 - accuracy: 0.6491 - val_loss: 0.6538 - val_accuracy: 0.7053 - 15ms/epoch - 5ms/step\n",
      "Epoch 77/100\n",
      "3/3 - 0s - loss: 0.7427 - accuracy: 0.6438 - val_loss: 0.6551 - val_accuracy: 0.6842 - 16ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "3/3 - 0s - loss: 0.7426 - accuracy: 0.6623 - val_loss: 0.6535 - val_accuracy: 0.6947 - 15ms/epoch - 5ms/step\n",
      "Epoch 79/100\n",
      "3/3 - 0s - loss: 0.7393 - accuracy: 0.6517 - val_loss: 0.6481 - val_accuracy: 0.7158 - 16ms/epoch - 5ms/step\n",
      "Epoch 80/100\n",
      "3/3 - 0s - loss: 0.7370 - accuracy: 0.6544 - val_loss: 0.6472 - val_accuracy: 0.7158 - 16ms/epoch - 5ms/step\n",
      "Epoch 81/100\n",
      "3/3 - 0s - loss: 0.7352 - accuracy: 0.6517 - val_loss: 0.6479 - val_accuracy: 0.7158 - 15ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "3/3 - 0s - loss: 0.7342 - accuracy: 0.6596 - val_loss: 0.6485 - val_accuracy: 0.6842 - 16ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "3/3 - 0s - loss: 0.7316 - accuracy: 0.6728 - val_loss: 0.6435 - val_accuracy: 0.7263 - 15ms/epoch - 5ms/step\n",
      "Epoch 84/100\n",
      "3/3 - 0s - loss: 0.7298 - accuracy: 0.6517 - val_loss: 0.6413 - val_accuracy: 0.7158 - 15ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "3/3 - 0s - loss: 0.7286 - accuracy: 0.6517 - val_loss: 0.6407 - val_accuracy: 0.7263 - 16ms/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "3/3 - 0s - loss: 0.7268 - accuracy: 0.6649 - val_loss: 0.6418 - val_accuracy: 0.6947 - 16ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "3/3 - 0s - loss: 0.7260 - accuracy: 0.6649 - val_loss: 0.6400 - val_accuracy: 0.7158 - 18ms/epoch - 6ms/step\n",
      "Epoch 88/100\n",
      "3/3 - 0s - loss: 0.7248 - accuracy: 0.6728 - val_loss: 0.6419 - val_accuracy: 0.7053 - 16ms/epoch - 5ms/step\n",
      "Epoch 89/100\n",
      "3/3 - 0s - loss: 0.7220 - accuracy: 0.6702 - val_loss: 0.6377 - val_accuracy: 0.7158 - 16ms/epoch - 5ms/step\n",
      "Epoch 90/100\n",
      "3/3 - 0s - loss: 0.7211 - accuracy: 0.6781 - val_loss: 0.6349 - val_accuracy: 0.7158 - 17ms/epoch - 6ms/step\n",
      "Epoch 91/100\n",
      "3/3 - 0s - loss: 0.7194 - accuracy: 0.6755 - val_loss: 0.6380 - val_accuracy: 0.7158 - 16ms/epoch - 5ms/step\n",
      "Epoch 92/100\n",
      "3/3 - 0s - loss: 0.7187 - accuracy: 0.6728 - val_loss: 0.6381 - val_accuracy: 0.7053 - 16ms/epoch - 5ms/step\n",
      "Epoch 93/100\n",
      "3/3 - 0s - loss: 0.7167 - accuracy: 0.6755 - val_loss: 0.6330 - val_accuracy: 0.7158 - 16ms/epoch - 5ms/step\n",
      "Epoch 94/100\n",
      "3/3 - 0s - loss: 0.7159 - accuracy: 0.6755 - val_loss: 0.6324 - val_accuracy: 0.7158 - 16ms/epoch - 5ms/step\n",
      "Epoch 95/100\n",
      "3/3 - 0s - loss: 0.7147 - accuracy: 0.6702 - val_loss: 0.6349 - val_accuracy: 0.7158 - 17ms/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "3/3 - 0s - loss: 0.7127 - accuracy: 0.6728 - val_loss: 0.6347 - val_accuracy: 0.7158 - 16ms/epoch - 5ms/step\n",
      "Epoch 97/100\n",
      "3/3 - 0s - loss: 0.7113 - accuracy: 0.6755 - val_loss: 0.6296 - val_accuracy: 0.7158 - 17ms/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "3/3 - 0s - loss: 0.7101 - accuracy: 0.6887 - val_loss: 0.6296 - val_accuracy: 0.7158 - 16ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "3/3 - 0s - loss: 0.7115 - accuracy: 0.6860 - val_loss: 0.6356 - val_accuracy: 0.7053 - 16ms/epoch - 5ms/step\n",
      "Epoch 100/100\n",
      "3/3 - 0s - loss: 0.7082 - accuracy: 0.6728 - val_loss: 0.6278 - val_accuracy: 0.7158 - 16ms/epoch - 5ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainX,trainY,epochs=100, batch_size=128, verbose=2,validation_split=0.2,callbacks = [callback])\n",
    "# history = model.fit(trainX,trainY,epochs=100, batch_size=12, verbose=2,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "706b691a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.6492 - accuracy: 0.7143 - 11ms/epoch - 11ms/step\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(testX,testY, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5227a04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa5ad96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('model/fcn11.h5')\n",
    "# model = load_model('fcn11.h5')\n",
    "# testPredict = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d55b66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.17242746e-02, 2.23146409e-01, 7.65129268e-01],\n",
       "       [5.76221406e-01, 3.27096254e-01, 9.66823250e-02],\n",
       "       [8.16673756e-01, 1.69626504e-01, 1.36997635e-02],\n",
       "       [6.94589972e-01, 2.81336099e-01, 2.40739994e-02],\n",
       "       [5.02105355e-01, 3.90928149e-01, 1.06966555e-01],\n",
       "       [3.23836431e-02, 3.91554862e-01, 5.76061487e-01],\n",
       "       [2.99441934e-01, 5.43703556e-01, 1.56854555e-01],\n",
       "       [3.93816113e-01, 4.58943516e-01, 1.47240415e-01],\n",
       "       [5.42961478e-01, 4.02028322e-01, 5.50102517e-02],\n",
       "       [7.23983049e-01, 2.52425432e-01, 2.35914364e-02],\n",
       "       [5.98884821e-01, 3.60729873e-01, 4.03853282e-02],\n",
       "       [4.02089953e-03, 1.13204807e-01, 8.82774293e-01],\n",
       "       [6.98535562e-01, 2.68074483e-01, 3.33899409e-02],\n",
       "       [3.08503747e-01, 4.80565220e-01, 2.10931078e-01],\n",
       "       [3.66360605e-01, 3.57404321e-01, 2.76235104e-01],\n",
       "       [5.78432083e-01, 3.21350366e-01, 1.00217551e-01],\n",
       "       [3.71914148e-01, 4.54255134e-01, 1.73830703e-01],\n",
       "       [6.69248462e-01, 2.98399270e-01, 3.23522724e-02],\n",
       "       [8.18778992e-01, 1.62455484e-01, 1.87654570e-02],\n",
       "       [6.15272701e-01, 3.49231958e-01, 3.54953818e-02],\n",
       "       [2.50183102e-02, 1.54302105e-01, 8.20679545e-01],\n",
       "       [1.64232731e-01, 4.81605917e-01, 3.54161322e-01],\n",
       "       [6.09304368e-01, 3.56841832e-01, 3.38538401e-02],\n",
       "       [2.84914434e-01, 5.72265804e-01, 1.42819777e-01],\n",
       "       [6.81388438e-01, 2.83840925e-01, 3.47706079e-02],\n",
       "       [2.98024900e-03, 9.45494398e-02, 9.02470350e-01],\n",
       "       [1.32356241e-01, 4.16044176e-01, 4.51599658e-01],\n",
       "       [7.87556946e-01, 1.89967707e-01, 2.24752948e-02],\n",
       "       [7.45221600e-03, 3.03546250e-01, 6.89001501e-01],\n",
       "       [3.67561638e-01, 4.78892028e-01, 1.53546318e-01],\n",
       "       [7.82357395e-01, 1.98025391e-01, 1.96172185e-02],\n",
       "       [1.56591013e-01, 3.63608420e-01, 4.79800522e-01],\n",
       "       [1.41376234e-03, 1.13953494e-01, 8.84632766e-01],\n",
       "       [7.22011030e-01, 2.37826839e-01, 4.01621349e-02],\n",
       "       [7.91917443e-01, 1.82810321e-01, 2.52721999e-02],\n",
       "       [6.39179409e-01, 3.15816969e-01, 4.50036153e-02],\n",
       "       [1.50761036e-02, 2.16676071e-01, 7.68247783e-01],\n",
       "       [6.39482617e-01, 3.00477713e-01, 6.00396544e-02],\n",
       "       [2.77606916e-04, 3.11656445e-02, 9.68556762e-01],\n",
       "       [1.62520036e-01, 5.73549926e-01, 2.63930082e-01],\n",
       "       [8.37476611e-01, 1.49276406e-01, 1.32469628e-02],\n",
       "       [5.29666170e-02, 3.32520455e-01, 6.14512920e-01],\n",
       "       [6.21897340e-01, 3.48139286e-01, 2.99633890e-02],\n",
       "       [7.46927559e-02, 3.90770316e-01, 5.34536898e-01],\n",
       "       [1.95587486e-01, 4.81293291e-01, 3.23119253e-01],\n",
       "       [2.68662372e-03, 1.60766423e-01, 8.36546898e-01],\n",
       "       [3.15167417e-04, 4.38926220e-02, 9.55792248e-01],\n",
       "       [2.96080858e-01, 5.06586194e-01, 1.97332948e-01],\n",
       "       [1.28071934e-01, 5.67346871e-01, 3.04581195e-01],\n",
       "       [1.48055211e-01, 4.76378173e-01, 3.75566572e-01],\n",
       "       [9.96240154e-02, 6.24615729e-01, 2.75760233e-01],\n",
       "       [4.57643494e-02, 1.77981213e-01, 7.76254475e-01],\n",
       "       [6.51161313e-01, 2.89112568e-01, 5.97261153e-02],\n",
       "       [2.07936261e-02, 1.87096745e-01, 7.92109609e-01],\n",
       "       [3.35928127e-02, 2.41153166e-01, 7.25254059e-01],\n",
       "       [1.04983680e-01, 5.25263548e-01, 3.69752824e-01],\n",
       "       [6.20437086e-01, 3.07210058e-01, 7.23528340e-02],\n",
       "       [9.12166119e-01, 8.22008625e-02, 5.63295092e-03],\n",
       "       [2.40630478e-01, 4.96149451e-01, 2.63220072e-01],\n",
       "       [4.31655854e-01, 4.03901219e-01, 1.64442882e-01],\n",
       "       [8.47990692e-01, 1.44579276e-01, 7.43003935e-03],\n",
       "       [4.92281973e-01, 3.67757291e-01, 1.39960751e-01],\n",
       "       [4.03712571e-01, 4.40809846e-01, 1.55477613e-01],\n",
       "       [9.78325214e-03, 3.09744537e-01, 6.80472195e-01],\n",
       "       [7.22315550e-01, 2.52173692e-01, 2.55107209e-02],\n",
       "       [1.65515412e-02, 2.12537169e-01, 7.70911276e-01],\n",
       "       [4.99138422e-03, 1.25708178e-01, 8.69300425e-01],\n",
       "       [2.35185593e-01, 4.94125634e-01, 2.70688802e-01],\n",
       "       [3.02045438e-02, 2.96988040e-01, 6.72807395e-01],\n",
       "       [4.76164324e-03, 2.18356028e-01, 7.76882291e-01],\n",
       "       [1.11032635e-01, 6.05306447e-01, 2.83660889e-01],\n",
       "       [4.75292876e-02, 4.13207442e-01, 5.39263248e-01],\n",
       "       [3.97063553e-01, 5.14012098e-01, 8.89242887e-02],\n",
       "       [3.20918043e-03, 1.18477717e-01, 8.78313124e-01],\n",
       "       [2.84486532e-01, 5.15640378e-01, 1.99873060e-01],\n",
       "       [5.77869236e-01, 3.72126162e-01, 5.00045978e-02],\n",
       "       [5.68711996e-01, 3.87118757e-01, 4.41691950e-02],\n",
       "       [7.43735135e-01, 2.35001057e-01, 2.12638006e-02],\n",
       "       [2.21567228e-02, 1.95549324e-01, 7.82293916e-01],\n",
       "       [1.54974520e-01, 5.86368442e-01, 2.58657068e-01],\n",
       "       [4.02403802e-01, 4.38723058e-01, 1.58873022e-01],\n",
       "       [3.62170935e-02, 3.52138340e-01, 6.11644566e-01],\n",
       "       [7.66383588e-01, 2.09827185e-01, 2.37892549e-02],\n",
       "       [3.88225392e-02, 2.41532207e-01, 7.19645262e-01],\n",
       "       [1.76901564e-01, 4.98113334e-01, 3.24985087e-01],\n",
       "       [2.92415410e-01, 5.26808619e-01, 1.80775955e-01],\n",
       "       [8.83131206e-01, 1.08085565e-01, 8.78322590e-03],\n",
       "       [2.22809494e-01, 5.44400811e-01, 2.32789725e-01],\n",
       "       [2.99627148e-03, 6.49892241e-02, 9.32014525e-01],\n",
       "       [7.02034868e-03, 2.58884966e-01, 7.34094620e-01],\n",
       "       [1.00532822e-01, 5.27709723e-01, 3.71757418e-01],\n",
       "       [1.42668948e-01, 6.11509621e-01, 2.45821431e-01],\n",
       "       [1.21496335e-01, 3.75814974e-01, 5.02688706e-01],\n",
       "       [1.10415094e-01, 5.42006195e-01, 3.47578764e-01],\n",
       "       [4.89154875e-01, 4.33657050e-01, 7.71880075e-02],\n",
       "       [2.82882988e-01, 4.70868975e-01, 2.46248007e-01],\n",
       "       [6.39187470e-02, 4.73595262e-01, 4.62485969e-01],\n",
       "       [7.62540400e-01, 2.05085337e-01, 3.23742703e-02],\n",
       "       [2.07819440e-03, 9.41606835e-02, 9.03761148e-01],\n",
       "       [2.74964929e-01, 4.72039431e-01, 2.52995670e-01],\n",
       "       [4.72741313e-02, 3.28904480e-01, 6.23821318e-01],\n",
       "       [4.46775369e-02, 3.23397964e-01, 6.31924510e-01],\n",
       "       [6.95255816e-01, 2.68035889e-01, 3.67082134e-02],\n",
       "       [7.06783593e-01, 2.65783489e-01, 2.74329334e-02],\n",
       "       [6.47106886e-01, 3.07946384e-01, 4.49466594e-02],\n",
       "       [4.23617894e-03, 1.55985862e-01, 8.39778006e-01],\n",
       "       [6.52492106e-01, 2.99425840e-01, 4.80820835e-02],\n",
       "       [8.15376714e-02, 5.93048036e-01, 3.25414270e-01],\n",
       "       [1.66569967e-02, 2.62615114e-01, 7.20727861e-01],\n",
       "       [4.89207596e-01, 4.27383542e-01, 8.34089145e-02],\n",
       "       [5.16815722e-01, 4.21073973e-01, 6.21102341e-02],\n",
       "       [8.48654091e-01, 1.43014193e-01, 8.33172724e-03],\n",
       "       [3.57370049e-01, 5.53792953e-01, 8.88369232e-02],\n",
       "       [7.67579360e-04, 4.43073101e-02, 9.54925060e-01],\n",
       "       [3.14443372e-04, 3.50573249e-02, 9.64628279e-01],\n",
       "       [2.64416039e-02, 3.01499665e-01, 6.72058761e-01],\n",
       "       [4.09742678e-03, 1.80710807e-01, 8.15191686e-01],\n",
       "       [6.96441293e-01, 2.65229434e-01, 3.83293107e-02],\n",
       "       [3.01391482e-01, 4.92298961e-01, 2.06309572e-01]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a72e39a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testPredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88713d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(testPredict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c06dd8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 0, 0, 2, 1,\n",
       "       0, 1, 0, 2, 2, 0, 2, 1, 0, 2, 2, 0, 0, 0, 2, 0, 2, 1, 0, 2, 0, 2,\n",
       "       1, 2, 2, 1, 1, 1, 1, 2, 0, 2, 2, 1, 0, 0, 1, 0, 0, 0, 1, 2, 0, 2,\n",
       "       2, 1, 2, 2, 1, 2, 1, 2, 1, 0, 0, 0, 2, 1, 1, 2, 0, 2, 1, 1, 0, 1,\n",
       "       2, 2, 1, 1, 2, 1, 0, 1, 1, 0, 2, 1, 2, 2, 0, 0, 0, 2, 0, 1, 2, 0,\n",
       "       0, 0, 1, 2, 2, 2, 2, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fdcd1ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_real = np.argmax(testY, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa8216de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 0, 1, 2, 1, 1, 0, 0, 1, 2, 1, 1, 0, 1, 1, 0, 0, 1, 2, 2,\n",
       "       0, 1, 0, 2, 2, 0, 1, 1, 0, 1, 2, 0, 0, 1, 1, 0, 2, 0, 0, 2, 1, 1,\n",
       "       1, 2, 2, 2, 1, 0, 1, 2, 1, 2, 2, 1, 0, 0, 1, 1, 0, 0, 1, 2, 0, 2,\n",
       "       2, 1, 1, 2, 2, 2, 1, 2, 1, 1, 0, 0, 1, 0, 1, 2, 0, 2, 2, 1, 0, 1,\n",
       "       2, 2, 2, 1, 2, 1, 1, 1, 2, 0, 2, 2, 1, 2, 0, 1, 0, 2, 1, 2, 2, 1,\n",
       "       0, 0, 2, 2, 2, 2, 2, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f17f3971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5733417694822314"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "kappa = cohen_kappa_score(y_real,y_pred)\n",
    "# kappa = cohen_kappa_score(dataY[-30:],y_pred)\n",
    "#(label除非是你想计算其中的分类子集的kappa系数，否则不需要设置)\n",
    "kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84b63078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2828131a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.91      0.78        34\n",
      "           1       0.62      0.50      0.55        42\n",
      "           2       0.82      0.77      0.80        43\n",
      "\n",
      "    accuracy                           0.71       119\n",
      "   macro avg       0.71      0.73      0.71       119\n",
      "weighted avg       0.71      0.71      0.71       119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_real,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba4f13b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('fcn111.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af4c62bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.6888888888888889,\n",
       "  'recall': 0.9117647058823529,\n",
       "  'f1-score': 0.7848101265822784,\n",
       "  'support': 34},\n",
       " '1': {'precision': 0.6176470588235294,\n",
       "  'recall': 0.5,\n",
       "  'f1-score': 0.5526315789473685,\n",
       "  'support': 42},\n",
       " '2': {'precision': 0.825,\n",
       "  'recall': 0.7674418604651163,\n",
       "  'f1-score': 0.7951807228915662,\n",
       "  'support': 43},\n",
       " 'accuracy': 0.7142857142857143,\n",
       " 'macro avg': {'precision': 0.710511982570806,\n",
       "  'recall': 0.7264021887824897,\n",
       "  'f1-score': 0.710874142807071,\n",
       "  'support': 119},\n",
       " 'weighted avg': {'precision': 0.7129277201076509,\n",
       "  'recall': 0.7142857142857143,\n",
       "  'f1-score': 0.7066121151590276,\n",
       "  'support': 119}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_real,y_pred,output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce5245d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c44879e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
